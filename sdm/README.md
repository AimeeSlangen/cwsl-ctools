# Data Extraction Scripts for Statistical Downscaling Model

The data extraction (DXT) tool for Statistical Downscaling Model (SDM) are a set
of Python command-line scripts that takes a Change-of-Date (CoD) file and
generates reconstructed daily climate series based on the AWAP local observation
dataset. 


## Description 
### Scope
The DXT tool focuses on the raw data extraction part without any
post-processing. The following steps describes the logical process for
running the DXT tool: 

1. An user specifies a set of parameters that are required to locate the corresponding
   CoD file:
    * Model (specify one model from a pre-defined list of 22 CMIP5 models)
    * Scenario (specify one scenario from a pre-defined list of 3 scenarios)
    * region (specify one region from a pre-defined list of 10 climate regions)
    * season (specify one season from a pre-defined list of 4 seasons)
    * predictand (specify one predictand from a pre-defined list of 3
      predictands)
2. The path to the CoD file is generated based on inputs from the previous
   step and the base directory of CoD files.
3. The reconstructed climate series is generated by picking up data from the
   AWAP dataset according to contents of the CoD File.
4. The output data is saved as a NetCDF file.

Any data post-processings, e.g. subsetting (date and region), inflation, tail
distribution correction, and visualisation, are **out of scope of the DXT
tool**. In Vistrails's terminology, these post-processing steps are separate
modules.

### Design
For better modularity, **the DXT tool itself will provide two modules for the
Vistrails system**. 

The **first module** takes user inputs of model, scenario, region, season and
predictand and outputs the path to the corresponding CoD file (essentially
covers step 1 and 2 in above listing).

The **second module** takes the path to the CoD file and input. It then reads
the specified CoD file, reconstruct the climate data series and outputs the data
as a CF-compliant NetCDF file (essentially covers step 3 and 4 in above
listing).

As the output NetCDF file is CF-compliant, it will be possible to use various
existing NetCDF processing tool (e.g. cdo, nco) for subsettings and
aggregations. A few SDM specific post-processings, e.g. inflation, may **not**
be possible to achieve with existing 3rd party tools and hence require dedicate
Python scripts to be developed. **They are by design out of scope of the DXT tool.
However, if time permits, the inflation post-processing will be looked into
further.**


## Python Version and Modules
* Python version 2.7+ 
* numpy 
* [netCDF4](http://netcdf4-python.googlecode.com/svn/trunk/docs/netCDF4-module.html)
* scipy (needed for most data post-processing modules except the simplest ones)

The code will be developed on a local machine and its final running environment
should be one of the NCI machines. As long as the requirement of Python version
and modules are met, the code shall be reasonably portable.


## Possible Issues
There maybe some memory issue on running the DXT tool as it requires large
memory to extract data for large regions (e.g. nmr, qld). Data post-processings
like inflation could be even more memory taxing. The tool will only guarantee to
work with smaller regions as memory issue is more hardware and operating system
related and cannot be easily solved in the code itself.


## Appendix
### List of Pre-defined Variables
#### Models
* ACCESS1.0
* ACCESS1.3
* BNU-ESM
* CCSM4
* CMCC-CMS
* CNRM-CM5
* CSIRO-Mk3.6.0
* CanESM2
* GFDL-ESM2G
* GFDL-ESM2M
* HadGEM2-CC
* IPSL-CM5A-LR
* IPSL-CM5A-MR
* IPSL-CM5B-LR
* MIROC-ESM-CHEM
* MIROC-ESM
* MIROC5
* MPI-ESM-LR
* MPI-ESM-MR
* MRI-CGCM3
* NorESM1-M
* bcc-csm1-1-m

#### Scenarios
* historical
* rcp45
* rcp85

#### Regions
* mec
* nmr
* nul
* nwa
* qld
* sea
* sec
* smd
* swc
* tas

#### Seasons
* DJF
* MAM
* JJA
* SON

#### Predictands
* rain
* tmin
* tmax

